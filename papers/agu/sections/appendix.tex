\label{sec:appendix}

\subsection{Reproducibility Details}
\label{sec:reproducibility}

\textbf{Computing Environment.} All processing was performed using Python 3.9.7 on Windows 11 with the following key dependencies:
\begin{itemize}
\item NumPy 1.21.5 (numerical computations)
\item GDAL 3.4.3 (geospatial data processing)
\item SciPy 1.8.0 (statistical analysis)
\item matplotlib 3.5.1 (visualization)
\item rasterio 1.2.10 (raster data I/O)
\end{itemize}

\textbf{Processing Commands.} All results can be reproduced using the following commands with fixed random seeds:
\begin{verbatim}
# XGM2019e gravity conversion (Section 2.1)
python convert_xgm_to_geotiff.py --region continental_usa 
       --resolution 111m --output data/processed/gravity/

# Multi-modal fusion and bidirectional detection
python multi_resolution_fusion.py --threshold 0.02 
       --validation enabled --seed 42

# Enhanced reporting and validation
python create_enhanced_reports.py --confidence_intervals 95
       --bootstrap_samples 1000
\end{verbatim}

\textbf{Random Seeds.} All stochastic processes use fixed seeds for reproducibility:
\begin{itemize}
\item NumPy random seed: 42
\item Bootstrap resampling: seed 1337
\item GDAL nodata value: -9999
\item Processing chunks: deterministic tiling (5000×5000 pixels)
\end{itemize}

\subsection{Implementation Details}
\label{sec:implementation}

\textbf{Memory Management.} Continental-scale processing uses tiled approach to manage memory constraints:
\begin{itemize}
\item Tile size: 5000×5000 pixels (~2.5 GB per tile)
\item Overlap: 500-pixel buffer to avoid edge artifacts
\item Peak memory usage: 12 GB for Continental USA processing
\item Parallel processing: NumPy vectorization, no explicit threading
\end{itemize}

\textbf{Data Quality Control.} Automated quality assessment for each data source:
\begin{itemize}
\item \textbf{XGM2019e gravity}: Uncertainty propagation from spherical harmonic coefficients
\item \textbf{EMAG2v3 magnetic}: Outlier detection using 3σ threshold
\item \textbf{NASADEM elevation}: Void detection and interpolation validation
\item \textbf{Missing data}: Nearest-neighbor interpolation for gaps <5 pixels
\end{itemize}

\textbf{Validation Framework.} Ground-truth validation features with geographic coordinates:
\begin{enumerate}
\item Carlsbad Caverns, NM (32.1753°N, 104.4458°W)
\item Meteor Crater, AZ (35.0280°N, 111.0221°W)
\item Berkeley Pit, MT (46.0085°N, 112.5001°W)
\item Homestake Mine, SD (44.3642°N, 103.7636°W)
\item Mammoth Cave, KY (37.1867°N, 86.1005°W)
\item Luray Caverns, VA (38.6651°N, 78.4845°W)
\item Wind Cave, SD (43.5580°N, 103.4778°W)
\item Jewel Cave, SD (43.7308°N, 103.8289°W)
\item Lechuguilla Cave, NM (32.1853°N, 104.4697°W)
\item Blanchard Springs Caverns, AR (35.9167°N, 92.0833°W)
\item Ruby Falls, TN (35.0197°N, 85.3122°W)
\item Natural Bridge Caverns, TX (29.6928°N, 98.3442°W)
\item Howe Caverns, NY (42.7000°N, 74.3969°W)
\item Oregon Caves, OR (42.0975°N, 123.4069°W)
\end{enumerate}

\subsection{Statistical Validation}
\label{sec:statistics}

\textbf{Bootstrap Confidence Intervals.} Performance metrics computed using bias-corrected and accelerated (BCa) bootstrap with 1000 resamples. Confidence intervals calculated as:
$$CI_{95\%} = [Q_{2.5\%}, Q_{97.5\%}]$$
where $Q_p$ represents the $p$-th percentile of bootstrap distribution.

\textbf{Hypothesis Testing.} Statistical significance assessed using:
\begin{itemize}
\item \textbf{Performance improvement}: Paired t-test on bootstrap samples
\item \textbf{Bidirectional distribution}: Chi-square goodness-of-fit test
\item \textbf{Spatial clustering}: Getis-Ord Gi* statistic for anomaly hotspots
\end{itemize}

\textbf{Effect Size Quantification.} Cohen's d calculated for performance improvements:
$$d = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}}$$
where subscripts 1,2 refer to bidirectional and traditional methods respectively.

\subsection{Computational Complexity Analysis}
\label{sec:complexity}

\textbf{Algorithm Complexity.} Bidirectional detection algorithm scales as:
\begin{itemize}
\item \textbf{Preprocessing}: $O(N)$ for $N$ pixels (linear in data size)
\item \textbf{Statistical normalization}: $O(N \log N)$ for sliding window operations
\item \textbf{Multi-modal fusion}: $O(N)$ for weighted combination
\item \textbf{Anomaly detection}: $O(N)$ for threshold application
\item \textbf{Overall complexity}: $O(N \log N)$ dominated by normalization step
\end{itemize}

\textbf{Scalability Projections.} Based on Continental USA processing (1.45 billion pixels):
\begin{itemize}
\item \textbf{Global coverage}: ~50 hours on standard hardware
\item \textbf{Memory scaling}: Linear with spatial extent
\item \textbf{I/O bottleneck}: Network bandwidth for data download
\item \textbf{Parallelization potential}: Embarrassingly parallel across tiles
\end{itemize}

\subsection{Error Analysis and Uncertainty Propagation}
\label{sec:error_analysis}

\textbf{Systematic Errors.} Potential sources of systematic bias:
\begin{itemize}
\item \textbf{XGM2019e resolution limits}: Features <5 km may be underrepresented
\item \textbf{EMAG2v3 reduction-to-pole}: Incomplete removal of magnetic inclination effects
\item \textbf{NASADEM void filling}: Interpolation artifacts in water bodies and steep terrain
\end{itemize}

\textbf{Random Errors.} Uncertainty propagation through processing chain:
$$\sigma_{total}^2 = \sum_{i} w_i^2 \sigma_i^2 + \sigma_{processing}^2$$
where $\sigma_i$ represents input data uncertainties and $\sigma_{processing}$ captures algorithmic noise.

\textbf{Validation Uncertainty.} Ground-truth feature locations have positional uncertainties:
\begin{itemize}
\item \textbf{Cave systems}: ±100m (entrance location vs. extent)
\item \textbf{Impact craters}: ±50m (rim definition ambiguity)
\item \textbf{Mining sites}: ±200m (operational area extent)
\end{itemize}

\subsection{Software Availability and Licensing}
\label{sec:software}

All processing software is available as open source under MIT license at:
\url{https://github.com/[repository-url]/GeoAnomalyMapper}

\textbf{Key Modules:}
\begin{itemize}
\item \texttt{convert\_xgm\_to\_geotiff.py}: Spherical harmonic gravity synthesis
\item \texttt{multi\_resolution\_fusion.py}: Bidirectional anomaly detection
\item \texttt{create\_enhanced\_reports.py}: Statistical validation and reporting
\end{itemize}

\textbf{Dependencies.} Installation follows the canonical metadata in \texttt{pyproject.toml} (``pip install -e .[all]``).  A Docker container may be constructed from the same definition for full reproducibility.

\textbf{Data Provenance.} All input datasets are freely available:
\begin{itemize}
\item XGM2019e: \url{http://icgem.gfz-potsdam.de/tom_longtime}
\item EMAG2v3: \url{https://www.ngdc.noaa.gov/geomag/emag2/}
\item NASADEM: \url{https://lpdaac.usgs.gov/products/nasadem_hgtv001/}
\end{itemize}